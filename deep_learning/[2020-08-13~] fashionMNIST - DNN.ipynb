{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch version: 1.5.0+cpu\n",
      "GPU 사용 가능 여부: False\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# import check_util.checker as checker \n",
    "\n",
    "print('pytorch version: {}'.format(torch.__version__))\n",
    "print('GPU 사용 가능 여부: {}'.format(torch.cuda.is_available()))\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "num_epochs = 5\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "root = './data'\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=(0.5,), std=(0.5,))])\n",
    "train_data = dset.FashionMNIST(root=root, train=True, transform=transform, download=True)\n",
    "test_data = dset.FashionMNIST(root=root, train=False, transform=transform, download=True)\n",
    "## 코드 시작 ##\n",
    "train_loader = DataLoader(dataset=train_data, \n",
    "                          batch_size=32, \n",
    "                          shuffle=True, \n",
    "                          num_workers=2)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_data, \n",
    "                          batch_size=32, \n",
    "                          shuffle=True, \n",
    "                          num_workers=2)\n",
    "## 코드 종료 ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_map = {0 : 'T-Shirt', 1 : 'Trouser', 2 : 'Pullover', 3 : 'Dress', 4 : 'Coat', 5 : 'Sandal', 6 : 'Shirt',\n",
    "              7 : 'Sneaker', 8 : 'Bag', 9 : 'Ankle Boot'}\n",
    "columns = 5\n",
    "rows = 5\n",
    "# fig = plt.figure(figsize=(8,8))\n",
    "\n",
    "# for i in range(1, columns*rows+1):\n",
    "#     data_idx = np.random.randint(len(train_data))\n",
    "#     img = train_data[data_idx][0][0,:,:].numpy() # numpy()를 통해 torch Tensor를 numpy array로 변환\n",
    "#     label = labels_map[train_data[data_idx][1]] # item()을 통해 torch Tensor를 숫자로 변환\n",
    "    \n",
    "#     fig.add_subplot(rows, columns, i)\n",
    "#     plt.title(label)\n",
    "# #     plt.imshow(img, cmap='gray')\n",
    "#     plt.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(DNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Linear(512, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Linear(128, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Linear(32,10)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1) # flatten\n",
    "        x_out = self.layer1(x)\n",
    "        x_out = self.layer2(x_out)\n",
    "        x_out = self.layer3(x_out)\n",
    "        x_out = self.layer4(x_out)\n",
    "\n",
    "        return x_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Linear): # 모델의 모든 MLP 레이어에 대해서\n",
    "        nn.init.xavier_normal_(m.weight) # Weight를 xavier_normal로 초기화\n",
    "        print(m.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0199,  0.0633, -0.0464,  ...,  0.0558,  0.0085,  0.1140],\n",
      "        [-0.1089, -0.0388,  0.0418,  ...,  0.0677,  0.0866, -0.1158],\n",
      "        [-0.0513, -0.0045, -0.0182,  ..., -0.0374,  0.0525,  0.0485],\n",
      "        ...,\n",
      "        [ 0.0277, -0.0726, -0.0044,  ...,  0.0335, -0.0817,  0.0323],\n",
      "        [ 0.0086, -0.0067,  0.0321,  ...,  0.0402,  0.0288, -0.0947],\n",
      "        [-0.0183, -0.0171, -0.0010,  ..., -0.0124,  0.0222, -0.0565]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-3.1014e-02, -4.6322e-02, -3.9021e-02,  ...,  4.3780e-02,\n",
      "         -6.3242e-02, -3.1698e-02],\n",
      "        [ 3.4446e-02,  5.1718e-02,  2.0039e-02,  ..., -3.5063e-05,\n",
      "          4.6842e-02, -7.9096e-02],\n",
      "        [-6.3938e-03, -4.2534e-02,  6.3819e-02,  ...,  1.2139e-02,\n",
      "         -3.1255e-02, -3.3414e-02],\n",
      "        ...,\n",
      "        [ 1.6447e-02,  1.8054e-02,  5.2685e-02,  ...,  3.2749e-02,\n",
      "         -8.8620e-02, -3.7797e-02],\n",
      "        [ 6.9293e-02,  3.6293e-02,  1.2373e-01,  ...,  5.5416e-02,\n",
      "         -4.4518e-02,  1.0673e-03],\n",
      "        [ 2.1110e-02,  1.1137e-01,  1.0776e-02,  ...,  7.5374e-02,\n",
      "          5.0490e-02,  1.7470e-02]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0905,  0.0470, -0.0128,  ..., -0.1053,  0.1167,  0.1557],\n",
      "        [ 0.0754, -0.0151,  0.1794,  ..., -0.0969,  0.0177,  0.1421],\n",
      "        [ 0.0395,  0.0351, -0.0847,  ...,  0.0640, -0.0918,  0.0375],\n",
      "        ...,\n",
      "        [ 0.0432, -0.0345, -0.2288,  ...,  0.0598,  0.3155,  0.1026],\n",
      "        [ 0.0318, -0.0320, -0.1352,  ...,  0.0714, -0.0027, -0.1151],\n",
      "        [ 0.1007, -0.0124,  0.1931,  ...,  0.0721,  0.0700,  0.0567]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.3620,  0.1527, -0.2375,  0.1889, -0.4104, -0.0377,  0.0216,  0.2503,\n",
      "          0.2843, -0.0309,  0.4530,  0.0429, -0.4464,  0.1537,  0.0827, -0.1014,\n",
      "         -0.0417,  0.1318, -0.0145,  0.1445, -0.0182,  0.0829,  0.1189,  0.0316,\n",
      "          0.2962,  0.0505,  0.0678,  0.0766, -0.0411, -0.2191,  0.0740, -0.2215],\n",
      "        [ 0.3856,  0.3447, -0.2853,  0.1083,  0.1909, -0.2020,  0.1131, -0.2153,\n",
      "          0.1201,  0.1923,  0.1754, -0.2207,  0.0707, -0.1886, -0.0916,  0.4274,\n",
      "          0.1911, -0.4076,  0.3183,  0.0396, -0.1165,  0.0521,  0.1854, -0.0098,\n",
      "          0.2530,  0.2003,  0.3331,  0.2054, -0.1321,  0.0280, -0.1127,  0.0131],\n",
      "        [ 0.4890, -0.0225, -0.2655, -0.0255, -0.0793,  0.0034,  0.0107, -0.1867,\n",
      "         -0.2257, -0.2506,  0.3262, -0.2577,  0.0760, -0.0248, -0.1872,  0.2242,\n",
      "         -0.1756, -0.1842, -0.1666,  0.1397, -0.0127, -0.1580, -0.0387,  0.1516,\n",
      "          0.3686,  0.0702,  0.1374, -0.2327, -0.1454,  0.0012, -0.0551, -0.0178],\n",
      "        [-0.0082, -0.1595,  0.1472,  0.1149,  0.0656, -0.1693,  0.1189,  0.1718,\n",
      "         -0.1432,  0.1737, -0.0306,  0.0624,  0.2279,  0.0984,  0.3001, -0.0631,\n",
      "          0.1195, -0.1807, -0.0441, -0.0554,  0.4533,  0.0550,  0.0598, -0.3452,\n",
      "         -0.1348, -0.1332,  0.1442, -0.1668, -0.0798, -0.1698,  0.2690,  0.0039],\n",
      "        [-0.0222, -0.4241, -0.1128,  0.0314, -0.1596, -0.2966, -0.0980, -0.1218,\n",
      "         -0.2652,  0.2205, -0.0312,  0.5508, -0.0748,  0.1275, -0.2346,  0.1435,\n",
      "          0.1514,  0.0960, -0.1568,  0.1968, -0.1513,  0.1821, -0.2517,  0.0741,\n",
      "         -0.1165,  0.1338, -0.1245, -0.2375, -0.0096,  0.1269,  0.0440, -0.1517],\n",
      "        [-0.2077, -0.0872, -0.0023, -0.1144, -0.1311,  0.2572, -0.1506,  0.1432,\n",
      "          0.0799,  0.0724,  0.1690, -0.0391, -0.0319, -0.4648,  0.0480,  0.2346,\n",
      "          0.3322,  0.2109,  0.1147,  0.1403,  0.0955, -0.0376,  0.1003,  0.1485,\n",
      "          0.0957,  0.3209, -0.1520,  0.1275, -0.0713, -0.2705,  0.2728, -0.0222],\n",
      "        [-0.2425,  0.2891, -0.2695,  0.0330,  0.0032,  0.1524, -0.0592, -0.5912,\n",
      "          0.0204,  0.0097, -0.2842,  0.2602,  0.1225,  0.1821, -0.0056, -0.0625,\n",
      "          0.0602,  0.0365, -0.3813, -0.0116,  0.1653,  0.5789, -0.2356, -0.0060,\n",
      "          0.0441,  0.1054, -0.1613, -0.2022, -0.2750, -0.1940,  0.2383, -0.4120],\n",
      "        [ 0.7397,  0.1016,  0.0523, -0.2534, -0.0415, -0.0658, -0.0930,  0.0928,\n",
      "          0.2716, -0.1481,  0.1054, -0.0045, -0.1626,  0.2033,  0.1395, -0.0371,\n",
      "         -0.0041, -0.2801, -0.1112,  0.1674,  0.0187,  0.2598,  0.2549, -0.0325,\n",
      "         -0.0439,  0.5736, -0.2201, -0.2110, -0.1967, -0.2886,  0.5889, -0.0890],\n",
      "        [ 0.2423,  0.0276, -0.1294, -0.1333, -0.1422,  0.1095,  0.1978,  0.0706,\n",
      "          0.0628, -0.0232, -0.0339,  0.2930,  0.1729, -0.4162,  0.1506, -0.0794,\n",
      "          0.1570,  0.1663,  0.4883,  0.0864, -0.4702, -0.0112, -0.2553, -0.1674,\n",
      "         -0.0265, -0.1935, -0.3620,  0.0356, -0.0540, -0.0479, -0.3351,  0.2318],\n",
      "        [-0.2140,  0.1004,  0.1960,  0.3395,  0.0087,  0.3928,  0.0960,  0.0977,\n",
      "          0.2769, -0.0374, -0.1045,  0.0070,  0.0042,  0.0236, -0.0908, -0.2824,\n",
      "         -0.1833, -0.1995,  0.3498, -0.1621,  0.1652,  0.1373,  0.3502,  0.0741,\n",
      "          0.1129,  0.0940,  0.1209,  0.2011, -0.0286,  0.0267, -0.0608, -0.2826]],\n",
      "       requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNN(\n",
       "  (layer1): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=128, bias=True)\n",
       "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=32, bias=True)\n",
       "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Linear(in_features=32, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(7777) # 일관된 weight initialization을 위한 random seed 설정\n",
    "model = DNN().to(device)\n",
    "model.apply(weights_init) # 모델에 weight_init 함수를 적용하여 weight를 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x17c698bcb08>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/1875], Loss: 0.8865, Accuracy: 71.88%\n",
      "Epoch [1/5], Step [200/1875], Loss: 0.6996, Accuracy: 78.12%\n",
      "Epoch [1/5], Step [300/1875], Loss: 0.5967, Accuracy: 84.38%\n",
      "Epoch [1/5], Step [400/1875], Loss: 0.5960, Accuracy: 71.88%\n",
      "Epoch [1/5], Step [500/1875], Loss: 0.8688, Accuracy: 68.75%\n",
      "Epoch [1/5], Step [600/1875], Loss: 0.4206, Accuracy: 84.38%\n",
      "Epoch [1/5], Step [700/1875], Loss: 0.5857, Accuracy: 81.25%\n",
      "Epoch [1/5], Step [800/1875], Loss: 0.4237, Accuracy: 84.38%\n",
      "Epoch [1/5], Step [900/1875], Loss: 0.2859, Accuracy: 87.50%\n",
      "Epoch [1/5], Step [1000/1875], Loss: 0.2824, Accuracy: 90.62%\n",
      "Epoch [1/5], Step [1100/1875], Loss: 0.4811, Accuracy: 78.12%\n",
      "Epoch [1/5], Step [1200/1875], Loss: 0.3787, Accuracy: 81.25%\n",
      "Epoch [1/5], Step [1300/1875], Loss: 0.2417, Accuracy: 90.62%\n",
      "Epoch [1/5], Step [1400/1875], Loss: 0.2560, Accuracy: 93.75%\n",
      "Epoch [1/5], Step [1500/1875], Loss: 0.6044, Accuracy: 75.00%\n",
      "Epoch [1/5], Step [1600/1875], Loss: 0.4351, Accuracy: 84.38%\n",
      "Epoch [1/5], Step [1700/1875], Loss: 0.3483, Accuracy: 90.62%\n",
      "Epoch [1/5], Step [1800/1875], Loss: 0.2806, Accuracy: 87.50%\n",
      "Epoch [2/5], Step [100/1875], Loss: 0.1894, Accuracy: 96.88%\n",
      "Epoch [2/5], Step [200/1875], Loss: 0.4547, Accuracy: 87.50%\n",
      "Epoch [2/5], Step [300/1875], Loss: 0.1822, Accuracy: 90.62%\n",
      "Epoch [2/5], Step [400/1875], Loss: 0.6220, Accuracy: 84.38%\n",
      "Epoch [2/5], Step [500/1875], Loss: 0.2606, Accuracy: 84.38%\n",
      "Epoch [2/5], Step [600/1875], Loss: 0.3007, Accuracy: 90.62%\n",
      "Epoch [2/5], Step [700/1875], Loss: 0.4766, Accuracy: 81.25%\n",
      "Epoch [2/5], Step [800/1875], Loss: 0.4047, Accuracy: 87.50%\n",
      "Epoch [2/5], Step [900/1875], Loss: 0.1711, Accuracy: 96.88%\n",
      "Epoch [2/5], Step [1000/1875], Loss: 0.1036, Accuracy: 96.88%\n",
      "Epoch [2/5], Step [1100/1875], Loss: 0.1635, Accuracy: 90.62%\n",
      "Epoch [2/5], Step [1200/1875], Loss: 0.3016, Accuracy: 87.50%\n",
      "Epoch [2/5], Step [1300/1875], Loss: 0.1879, Accuracy: 93.75%\n",
      "Epoch [2/5], Step [1400/1875], Loss: 0.6444, Accuracy: 78.12%\n",
      "Epoch [2/5], Step [1500/1875], Loss: 0.3811, Accuracy: 84.38%\n",
      "Epoch [2/5], Step [1600/1875], Loss: 0.6356, Accuracy: 75.00%\n",
      "Epoch [2/5], Step [1700/1875], Loss: 0.2675, Accuracy: 87.50%\n",
      "Epoch [2/5], Step [1800/1875], Loss: 0.4443, Accuracy: 93.75%\n",
      "Epoch [3/5], Step [100/1875], Loss: 0.2303, Accuracy: 93.75%\n",
      "Epoch [3/5], Step [200/1875], Loss: 0.3987, Accuracy: 81.25%\n",
      "Epoch [3/5], Step [300/1875], Loss: 0.2304, Accuracy: 87.50%\n",
      "Epoch [3/5], Step [400/1875], Loss: 0.3820, Accuracy: 90.62%\n",
      "Epoch [3/5], Step [500/1875], Loss: 0.6332, Accuracy: 75.00%\n",
      "Epoch [3/5], Step [600/1875], Loss: 0.3478, Accuracy: 87.50%\n",
      "Epoch [3/5], Step [700/1875], Loss: 0.4301, Accuracy: 84.38%\n",
      "Epoch [3/5], Step [800/1875], Loss: 0.3110, Accuracy: 87.50%\n",
      "Epoch [3/5], Step [900/1875], Loss: 0.2130, Accuracy: 90.62%\n",
      "Epoch [3/5], Step [1000/1875], Loss: 0.3264, Accuracy: 87.50%\n",
      "Epoch [3/5], Step [1100/1875], Loss: 0.3464, Accuracy: 81.25%\n",
      "Epoch [3/5], Step [1200/1875], Loss: 0.2791, Accuracy: 87.50%\n",
      "Epoch [3/5], Step [1300/1875], Loss: 0.2671, Accuracy: 96.88%\n",
      "Epoch [3/5], Step [1400/1875], Loss: 0.3555, Accuracy: 87.50%\n",
      "Epoch [3/5], Step [1500/1875], Loss: 0.1972, Accuracy: 93.75%\n",
      "Epoch [3/5], Step [1600/1875], Loss: 0.2100, Accuracy: 87.50%\n",
      "Epoch [3/5], Step [1700/1875], Loss: 0.3614, Accuracy: 87.50%\n",
      "Epoch [3/5], Step [1800/1875], Loss: 0.3559, Accuracy: 90.62%\n",
      "Epoch [4/5], Step [100/1875], Loss: 0.1579, Accuracy: 93.75%\n",
      "Epoch [4/5], Step [200/1875], Loss: 0.2976, Accuracy: 87.50%\n",
      "Epoch [4/5], Step [300/1875], Loss: 0.1797, Accuracy: 93.75%\n",
      "Epoch [4/5], Step [400/1875], Loss: 0.2639, Accuracy: 93.75%\n",
      "Epoch [4/5], Step [500/1875], Loss: 0.7349, Accuracy: 71.88%\n",
      "Epoch [4/5], Step [600/1875], Loss: 0.2085, Accuracy: 96.88%\n",
      "Epoch [4/5], Step [700/1875], Loss: 0.1851, Accuracy: 93.75%\n",
      "Epoch [4/5], Step [800/1875], Loss: 0.2445, Accuracy: 81.25%\n",
      "Epoch [4/5], Step [900/1875], Loss: 0.1593, Accuracy: 93.75%\n",
      "Epoch [4/5], Step [1000/1875], Loss: 0.3198, Accuracy: 84.38%\n",
      "Epoch [4/5], Step [1100/1875], Loss: 0.3601, Accuracy: 84.38%\n",
      "Epoch [4/5], Step [1200/1875], Loss: 0.1704, Accuracy: 90.62%\n",
      "Epoch [4/5], Step [1300/1875], Loss: 0.3460, Accuracy: 81.25%\n",
      "Epoch [4/5], Step [1400/1875], Loss: 0.2772, Accuracy: 93.75%\n",
      "Epoch [4/5], Step [1500/1875], Loss: 0.2003, Accuracy: 90.62%\n",
      "Epoch [4/5], Step [1600/1875], Loss: 0.2856, Accuracy: 90.62%\n",
      "Epoch [4/5], Step [1700/1875], Loss: 0.1789, Accuracy: 90.62%\n",
      "Epoch [4/5], Step [1800/1875], Loss: 0.2276, Accuracy: 87.50%\n",
      "Epoch [5/5], Step [100/1875], Loss: 0.2232, Accuracy: 90.62%\n",
      "Epoch [5/5], Step [200/1875], Loss: 0.2702, Accuracy: 87.50%\n",
      "Epoch [5/5], Step [300/1875], Loss: 0.2470, Accuracy: 90.62%\n",
      "Epoch [5/5], Step [400/1875], Loss: 0.2909, Accuracy: 84.38%\n",
      "Epoch [5/5], Step [500/1875], Loss: 0.2031, Accuracy: 90.62%\n",
      "Epoch [5/5], Step [600/1875], Loss: 0.4608, Accuracy: 84.38%\n",
      "Epoch [5/5], Step [700/1875], Loss: 0.4024, Accuracy: 87.50%\n",
      "Epoch [5/5], Step [800/1875], Loss: 0.3386, Accuracy: 87.50%\n",
      "Epoch [5/5], Step [900/1875], Loss: 0.1053, Accuracy: 96.88%\n",
      "Epoch [5/5], Step [1000/1875], Loss: 0.2202, Accuracy: 90.62%\n",
      "Epoch [5/5], Step [1100/1875], Loss: 0.3594, Accuracy: 84.38%\n",
      "Epoch [5/5], Step [1200/1875], Loss: 0.3542, Accuracy: 84.38%\n",
      "Epoch [5/5], Step [1300/1875], Loss: 0.3838, Accuracy: 87.50%\n",
      "Epoch [5/5], Step [1400/1875], Loss: 0.3672, Accuracy: 87.50%\n",
      "Epoch [5/5], Step [1500/1875], Loss: 0.3113, Accuracy: 84.38%\n",
      "Epoch [5/5], Step [1600/1875], Loss: 0.1056, Accuracy: 96.88%\n",
      "Epoch [5/5], Step [1700/1875], Loss: 0.1072, Accuracy: 96.88%\n",
      "Epoch [5/5], Step [1800/1875], Loss: 0.2187, Accuracy: 90.62%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (imgs, labels) in enumerate(train_loader):\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        \n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        _, argmax = torch.max(outputs, 1)\n",
    "        accuracy = (labels == argmax).float().mean()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'.format(\n",
    "                epoch+1, num_epochs, i+1, len(train_loader), loss.item(), accuracy.item() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for 10000 images: 88.73%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (imgs, labels) in enumerate(test_loader):\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        outputs = model(imgs)\n",
    "        _, argmax = torch.max(outputs, 1) # max()를 통해 최종 출력이 가장 높은 class 선택\n",
    "        total += imgs.size(0)\n",
    "        correct += (labels == argmax).sum().item()\n",
    "    \n",
    "    print('Test accuracy for {} images: {:.2f}%'.format(total, correct / total * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dead kernel 발생하여 plot 하지 않음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = 5\n",
    "rows = 5\n",
    "# fig = plt.figure(figsize=(8,8))\n",
    "\n",
    "model.eval()\n",
    "for i in range(1, columns*rows+1):\n",
    "    data_idx = np.random.randint(len(test_data))\n",
    "    input_img = test_data[data_idx][0].unsqueeze(dim=0).to(device) \n",
    "    '''\n",
    "    unsqueeze()를 통해 입력 이미지의 shape을 (1, 28, 28)에서 (1, 1, 28, 28)로 변환. \n",
    "    모델에 들어가는 입력 이미지의 shape은 (batch_size, channel, width, height) 되어야 함에 주의하세요!\n",
    "    '''\n",
    "    output = model(input_img)\n",
    "    _, argmax = torch.max(output, 1)\n",
    "    pred = labels_map[argmax.item()]\n",
    "    label = labels_map[test_data[data_idx][1]]\n",
    "    \n",
    "#     fig.add_subplot(rows, columns, i)\n",
    "#     if pred == label:\n",
    "#         plt.title(pred + '(O)')\n",
    "#     else:\n",
    "#         plt.title(pred + '(X)' + ' / ' + label)\n",
    "#     plot_img = test_data[data_idx][0][0,:,:]\n",
    "#     plt.imshow(plot_img, cmap='gray')\n",
    "#     plt.axis('off')\n",
    "# model.train()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
