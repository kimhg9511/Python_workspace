{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# module import\n",
    "크롤링에 사용할 모듈을 import 합니다.\n",
    "## 사용 모듈 :\n",
    "### requests\n",
    "웹 request, response를 처리하기 위한 모듈\n",
    "### BeautifulSoup\n",
    "request의 html 데이터를 DOM Object처럼 처리하기 위한 모듈\n",
    "### time\n",
    "지연시간을 두어 반복문에 딜레이를 주기 위하여 사용( time.sleep(초))\n",
    "### ++ fileIO.py\n",
    "csv, json파일로 변환하기 위하여 따로 만든 py 파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time\n",
    "import fileIO as io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 뉴스 하나의 제목, 내용 가져오기\n",
    "## 필요한 정보\n",
    "### url 생성 \n",
    "https://news.v.daum.net/v/20200608091904580\n",
    "### 제목, 내용을 출력하는 element 파악(css selector)\n",
    "제목 : h3.tit_view\n",
    "내용 : div#harmonyContainer p (p태그 여러 개에 분할되어있음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title,content req: 200\n",
      "\"트럼프에 질렸다\" 부시·파월·롬니 등 공화당 거물들 반기 \n",
      "(서울=연합뉴스) 장재은 기자 = 도널드 트럼프 미국 대통령의 실정을 주장하며 반기를 드는 공화당 거물 인사들이 속출하고 있다고 미국 뉴욕타임스(NYT)가 7일(현지시간) 보도했\n"
     ]
    }
   ],
   "source": [
    "url = 'https://news.v.daum.net/v/20200608091904580'\n",
    "req = requests.get(url)\n",
    "# 페이지가 잘 로드되었는지 체크\n",
    "print('title,content req:',req.status_code)\n",
    "soup = bs(req.text, 'html.parser')\n",
    "# title\n",
    "news_title = soup.select_one('h3.tit_view').text\n",
    "# content\n",
    "news_content = \"\\n\".join(list(map(lambda i:i.text, soup.select('div#harmonyContainer p'))))\n",
    "# 본문 내용이 크므로 100글자만 출력(제대로 담겨있음)\n",
    "print(news_title, news_content[0:100]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 뉴스 하나의 댓글 가져오기\n",
    "## 필요한 정보\n",
    "### 댓글은 response가 도착했을 때 바로 오지 않음\n",
    "web의 network 탭에서 댓글을 불러오는 url을 찾아서 가공해야함.\n",
    "댓글 : headers에 Authorization 값을 첨부하여 params와 함께 요청\n",
    "댓글 개수 : params 없이 headers 값만 첨부하여 요청\n",
    "### 댓글은 한 번에 100개까지만 긁어올 수 있음\n",
    "반복문을 사용하여 100개씩 전부 가져오도록 설정.\n",
    "#### 변경해야 하는 값 : params\n",
    "offset\n",
    "limit\n",
    "### 댓글의 답글은 parentid값을 조정하여 다시 요청해야함\n",
    "#### 변경해야 하는 값 : params\n",
    "parentid\n",
    "### 댓글의 response data는 json 형태로 옴(list로 설정 가능)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:  1346 , current:  1346\n"
     ]
    }
   ],
   "source": [
    "# get comment count\n",
    "# 인증 값(web에서 찾아야 함)\n",
    "headers = { \n",
    "    'Authorization': 'Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJmb3J1bV9rZXkiOiJuZXdzIiwiZ3JhbnRfdHlwZSI6ImFsZXhfY3JlZGVudGlhbHMiLCJzY29wZSI6W10sImV4cCI6MTU5MTYyMDY1NiwiYXV0aG9yaXRpZXMiOlsiUk9MRV9DTElFTlQiXSwianRpIjoiMDhlYWUwMzEtMDczOC00MzQ2LTkyNWItOGNmYzYxYTg5ZTZhIiwiZm9ydW1faWQiOi05OSwiY2xpZW50X2lkIjoiMjZCWEF2S255NVdGNVowOWxyNWs3N1k4In0.H3kg5773Kx2ApM41gUC9aaIVzlAfcufck5d1oAN6JnI'\n",
    "}\n",
    "url = 'https://comment.daum.net/apis/v1/posts/@20200608091904580'\n",
    "req = requests.get(url, headers=headers)\n",
    "# print('commentCount req:',req.status_code)\n",
    "commentCount = req.json()['commentCount']\n",
    "commentCount\n",
    "# 댓글을 담을 리스트\n",
    "comments_list = []\n",
    "cnt = 0\n",
    "# cnt를 따로 설정한 이유? \n",
    "# comment_list의 값이 답글을 긁어오지 못하면 \n",
    "# commentCount값을 넘을 수 없기 때문.\n",
    "while int(commentCount / 100) >= cnt:\n",
    "    # url 가공\n",
    "    url = f'https://comment.daum.net/apis/v1/posts/@20200608091904580/comments'\n",
    "    params = f'parentId=0&offset={cnt*100}&limit=100&sort=CHRONOLOGICAL&isInitial=true'\n",
    "    params = list(map(lambda i: i.split('='),params.split('&')))\n",
    "    params = {k: v for k, v in params}\n",
    "    req = requests.get(url, headers=headers, params=params) \n",
    "    # response check\n",
    "#     print('comment req:',req.status_code)\n",
    "    # json 가공\n",
    "    comments = list(map(lambda i:i['content'].replace('\\n',''), req.json()))\n",
    "    # list에 저장\n",
    "    comments_list.extend(comments)\n",
    "    cnt = cnt + 1\n",
    "#     # data 확인용 코드\n",
    "#     print('total: ', commentCount, ', current: ', len(comments_list))\n",
    "    # 지연 시간 설정(1초)\n",
    "    time.sleep(0.1)\n",
    "# 답글 긁어오기\n",
    "cnt = 0\n",
    "while int(commentCount / 100) >= cnt:\n",
    "    # url 가공\n",
    "    url = f'https://comment.daum.net/apis/v1/posts/@20200608091904580/comments'\n",
    "    params = f'parentId=-1&offset={cnt*100}&limit=100&sort=CHRONOLOGICAL&isInitial=true'\n",
    "    params = list(map(lambda i: i.split('='),params.split('&')))\n",
    "    params = {k: v for k, v in params}\n",
    "    headers = { \n",
    "        'Authorization': 'Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJmb3J1bV9rZXkiOiJuZXdzIiwiZ3JhbnRfdHlwZSI6ImFsZXhfY3JlZGVudGlhbHMiLCJzY29wZSI6W10sImV4cCI6MTU5MTYyMDY1NiwiYXV0aG9yaXRpZXMiOlsiUk9MRV9DTElFTlQiXSwianRpIjoiMDhlYWUwMzEtMDczOC00MzQ2LTkyNWItOGNmYzYxYTg5ZTZhIiwiZm9ydW1faWQiOi05OSwiY2xpZW50X2lkIjoiMjZCWEF2S255NVdGNVowOWxyNWs3N1k4In0.H3kg5773Kx2ApM41gUC9aaIVzlAfcufck5d1oAN6JnI'\n",
    "    }\n",
    "    # request\n",
    "    req = requests.get(url, headers=headers, params=params) \n",
    "#     print('comment req:',req.status_code)\n",
    "    comments = list(map(lambda i:i['content'].replace('\\n',''), req.json()))\n",
    "    comments_list.extend(comments)\n",
    "#     print('total: ', commentCount, ', current: ', len(comments_list))\n",
    "    cnt += 1\n",
    "    time.sleep(0.1)\n",
    "print('total: ', commentCount, ', current: ', len(comments_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 메인 페이지 뉴스 id 전부 가져오기\n",
    "## 필요한 정보\n",
    "### 뉴스 id는 17자리 숫자값\n",
    "### 뉴스 id를 가지고 있는 엘리먼트\n",
    "a.link_txt에서 추출\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# news list crawling\n",
    "def get_news_list():\n",
    "    main_req = requests.get('https://news.daum.net/')\n",
    "    main_soup = bs(main_req.text, 'html.parser')\n",
    "    news_list = list(map(lambda i:i.attrs['href'].split('/')[-1], main_soup.select('a.link_txt')))\n",
    "    cnt = 0\n",
    "    for i in range(len(news_list)):\n",
    "        if len(news_list[i - cnt]) != 17:\n",
    "            del news_list[i - cnt]\n",
    "            cnt += 1\n",
    "    return news_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 반복문으로 main에 있는 모든 뉴스의 제목, 내용, 댓글을 가져와 파일로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "news_id:  20200608141620614\n",
      "total:  6 , current:  6\n",
      "news_id:  20200608121431711\n",
      "total:  26 , current:  26\n",
      "news_id:  20200608115016828\n",
      "total:  1142 , current:  1142\n",
      "news_id:  20200608140654272\n",
      "total:  8 , current:  8\n",
      "news_id:  20200608120632547\n",
      "total:  6 , current:  6\n",
      "news_id:  20200608072704684\n",
      "total:  2 , current:  2\n",
      "news_id:  20200608140139080\n",
      "total:  6 , current:  6\n",
      "news_id:  20200608094010585\n",
      "total:  5 , current:  5\n",
      "news_id:  20200608083822013\n",
      "total:  5 , current:  5\n",
      "news_id:  20200608134349480\n",
      "total:  5 , current:  5\n",
      "news_id:  20200608121120666\n",
      "total:  16 , current:  16\n",
      "news_id:  20200608120145384\n",
      "total:  5 , current:  5\n",
      "news_id:  20200608140858319\n",
      "total:  2 , current:  2\n",
      "news_id:  20200608140412176\n",
      "total:  1 , current:  1\n",
      "news_id:  20200608140250119\n",
      "total:  7 , current:  7\n",
      "news_id:  20200608140219103\n",
      "total:  50 , current:  50\n",
      "news_id:  20200608140110070\n",
      "total:  2 , current:  2\n",
      "news_id:  20200608140013026\n",
      "total:  10 , current:  10\n",
      "news_id:  20200608135946996\n",
      "total:  51 , current:  51\n",
      "news_id:  20200608135602887\n",
      "total:  1 , current:  1\n",
      "news_id:  20200608135339796\n",
      "total:  2 , current:  2\n",
      "news_id:  20200608135319785\n",
      "total:  6 , current:  6\n",
      "news_id:  20200608135119730\n",
      "total:  16 , current:  16\n",
      "news_id:  20200608135106717\n",
      "total:  2 , current:  2\n",
      "news_id:  20200608101650623\n",
      "total:  375 , current:  375\n",
      "news_id:  20200608085716502\n",
      "total:  102 , current:  102\n",
      "news_id:  20200608131206697\n",
      "total:  130 , current:  130\n",
      "news_id:  20200608101014236\n",
      "total:  283 , current:  283\n",
      "news_id:  20200608102348020\n",
      "total:  5049 , current:  5051\n",
      "news_id:  20200608102223942\n",
      "total:  8697 , current:  8709\n",
      "news_id:  20200608102348020\n",
      "total:  5060 , current:  5060\n",
      "news_id:  20200608104627227\n",
      "total:  3417 , current:  3418\n",
      "news_id:  20200608114559634\n",
      "total:  2083 , current:  2083\n",
      "news_id:  20200608110417275\n",
      "total:  1475 , current:  1475\n",
      "news_id:  20200608134200411\n",
      "total:  1 , current:  1\n",
      "news_id:  20200608101823730\n",
      "total:  320 , current:  320\n",
      "news_id:  20200607200353186\n",
      "total:  6777 , current:  6777\n",
      "news_id:  20200607204805871\n",
      "total:  313 , current:  313\n",
      "news_id:  20200608090430885\n",
      "total:  652 , current:  652\n",
      "news_id:  20200608140219103\n",
      "total:  56 , current:  56\n",
      "news_id:  20200607173302805\n",
      "total:  1562 , current:  1562\n",
      "news_id:  20200607211024250\n",
      "total:  7820 , current:  7819\n",
      "**crawling complete**\n"
     ]
    }
   ],
   "source": [
    "# main의 모든 뉴스를 가져옴\n",
    "news_id_list = get_news_list()\n",
    "# 제목 list\n",
    "news_title_list = []\n",
    "# 내용 list\n",
    "news_content_list = []\n",
    "# 댓글 list\n",
    "comments_list_all = []\n",
    "# 인증 값(web에서 찾아야 함)\n",
    "headers = {'Authorization': 'Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJmb3J1bV9rZXkiOiJuZXdzIiwiZ3JhbnRfdHlwZSI6ImFsZXhfY3JlZGVudGlhbHMiLCJzY29wZSI6W10sImV4cCI6MTU5MTYyMDY1NiwiYXV0aG9yaXRpZXMiOlsiUk9MRV9DTElFTlQiXSwianRpIjoiMDhlYWUwMzEtMDczOC00MzQ2LTkyNWItOGNmYzYxYTg5ZTZhIiwiZm9ydW1faWQiOi05OSwiY2xpZW50X2lkIjoiMjZCWEF2S255NVdGNVowOWxyNWs3N1k4In0.H3kg5773Kx2ApM41gUC9aaIVzlAfcufck5d1oAN6JnI'}\n",
    "# csv 변환을 위한 list\n",
    "news_list = []\n",
    "# json 변환을 위한 dict\n",
    "news_json = {}\n",
    "\n",
    "for news_id in news_id_list:\n",
    "    print('news_id: ', news_id)\n",
    "# 제목, 내용  \n",
    "    url = f'https://news.v.daum.net/v/{news_id}'\n",
    "    req = requests.get(url)\n",
    "#     # 페이지가 잘 로드되었는지 체크\n",
    "#     print('title,content req:',req.status_code)\n",
    "    soup = bs(req.text, 'html.parser')\n",
    "    # title\n",
    "    news_title = soup.select_one('h3.tit_view').text\n",
    "    # content\n",
    "    news_content = \"\\n\".join(list(map(lambda i:i.text, soup.select('div#harmonyContainer p'))))\n",
    "# 댓글\n",
    "    # get comment count\n",
    "    url = f'https://comment.daum.net/apis/v1/posts/@{news_id}'\n",
    "    req = requests.get(url, headers=headers)\n",
    "#     print('commentCount req:',req.status_code)\n",
    "    commentCount = req.json()['commentCount']\n",
    "    commentCount\n",
    "    # 댓글을 담을 리스트\n",
    "    comments_list = []\n",
    "    cnt = 0\n",
    "    # cnt를 따로 설정한 이유? \n",
    "    # comment_list의 값이 답글을 긁어오지 못하면 \n",
    "    # commentCount값을 넘을 수 없기 때문.\n",
    "    while int(commentCount / 100) >= cnt:\n",
    "        # url 가공\n",
    "        url = f'https://comment.daum.net/apis/v1/posts/@{news_id}/comments'\n",
    "        params = f'parentId=0&offset={cnt*100}&limit=100&sort=CHRONOLOGICAL&isInitial=true'\n",
    "        params = list(map(lambda i: i.split('='),params.split('&')))\n",
    "        params = {k: v for k, v in params}\n",
    "        req = requests.get(url, headers=headers, params=params) \n",
    "        # response check\n",
    "#         print('comment req:',req.status_code)\n",
    "        # json 가공\n",
    "        comments = list(map(lambda i:i['content'].replace('\\n',''), req.json()))\n",
    "        # list에 저장\n",
    "        comments_list.extend(comments)\n",
    "        cnt = cnt + 1\n",
    "#         # data 확인용 코드\n",
    "#         print('total: ', commentCount, ', current: ', len(comments_list))\n",
    "        # 지연 시간 설정(1초)\n",
    "        time.sleep(0.1)\n",
    "    # 답글 긁어오기\n",
    "    cnt = 0\n",
    "    while int(commentCount / 100) >= cnt:\n",
    "        # url 가공\n",
    "        url = f'https://comment.daum.net/apis/v1/posts/@{news_id}/comments'\n",
    "        params = f'parentId=-1&offset={cnt*100}&limit=100&sort=CHRONOLOGICAL&isInitial=true'\n",
    "        params = list(map(lambda i: i.split('='),params.split('&')))\n",
    "        params = {k: v for k, v in params}\n",
    "        headers = { \n",
    "            'Authorization': 'Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJmb3J1bV9rZXkiOiJuZXdzIiwiZ3JhbnRfdHlwZSI6ImFsZXhfY3JlZGVudGlhbHMiLCJzY29wZSI6W10sImV4cCI6MTU5MTYyMDY1NiwiYXV0aG9yaXRpZXMiOlsiUk9MRV9DTElFTlQiXSwianRpIjoiMDhlYWUwMzEtMDczOC00MzQ2LTkyNWItOGNmYzYxYTg5ZTZhIiwiZm9ydW1faWQiOi05OSwiY2xpZW50X2lkIjoiMjZCWEF2S255NVdGNVowOWxyNWs3N1k4In0.H3kg5773Kx2ApM41gUC9aaIVzlAfcufck5d1oAN6JnI'\n",
    "        }\n",
    "        # request\n",
    "        req = requests.get(url, headers=headers, params=params) \n",
    "#         print('comment req:',req.status_code)\n",
    "        comments = list(map(lambda i:i['content'].replace('\\n',''), req.json()))\n",
    "        comments_list.extend(comments)\n",
    "#         print('total: ', commentCount, ', current: ', len(comments_list))\n",
    "        cnt += 1\n",
    "        time.sleep(0.1)\n",
    "    print('total: ', commentCount, ', current: ', len(comments_list))\n",
    "    news_title_list.append(news_title)\n",
    "    news_content_list.append(news_content)\n",
    "    comments_list_all.append(comments_list)\n",
    "    \n",
    "# list, dict로 통합\n",
    "news_list = [(news_title_list[i], news_content_list[i], comments_list_all[i]) for i in range(len(news_id_list))]\n",
    "news_json = [{'title': news_title_list[i], 'content': news_content_list[i], 'comments': comments_list_all[i]} for i in range(len(news_id_list))]    \n",
    "# 날짜를 이용하여 파일 이름 생성\n",
    "dt = time.strftime('%Y%m%d', time.localtime(time.time()))\n",
    "xml_file = 'forecast_'+ dt + '.xml'\n",
    "\n",
    "# 파일로 변환\n",
    "io.list_to_csv('news.csv', news_list)\n",
    "io.list_to_json('news.json', news_json)\n",
    "print('**crawling complete**')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 개선사항\n",
    "매일 Authorization 값이 바뀌어 자동화가 불가능\n",
    "\n",
    "search 페이지에서 모든 뉴스id 긁어오는 코드 작성 필요"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
