{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다음 뉴스 크롤링\n",
    "다음 뉴스 메인페이지에 있는 모든 뉴스를 리스트화 하여 제목, 내용, 댓글을 가져오는 코드입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# module import\n",
    "크롤링에 사용할 모듈을 import 합니다.\n",
    "## 사용 모듈 :\n",
    "### requests\n",
    "웹 request, response를 처리하기 위한 모듈\n",
    "### BeautifulSoup\n",
    "request의 html 데이터를 DOM Object처럼 처리하기 위한 모듈\n",
    "### time\n",
    "지연시간을 두어 반복문에 딜레이를 주기 위하여 사용( time.sleep(초))\n",
    "### ++ fileIO.py\n",
    "csv, json파일로 변환하기 위하여 따로 만든 py 파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time\n",
    "import fileIO as io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 뉴스 하나의 제목, 내용 가져오기\n",
    "## 필요한 정보\n",
    "### url 생성 \n",
    "https://news.v.daum.net/v/20200608091904580\n",
    "### 제목, 내용을 출력하는 element 파악(css selector)\n",
    "제목 : h3.tit_view\n",
    "내용 : div#harmonyContainer p (p태그 여러 개에 분할되어있음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title,content req: 200\n",
      "\"트럼프에 질렸다\" 부시·파월·롬니 등 공화당 거물들 반기 \n",
      "(서울=연합뉴스) 장재은 기자 = 도널드 트럼프 미국 대통령의 실정을 주장하며 반기를 드는 공화당 거물 인사들이 속출하고 있다고 미국 뉴욕타임스(NYT)가 7일(현지시간) 보도했\n"
     ]
    }
   ],
   "source": [
    "url = 'https://news.v.daum.net/v/20200608091904580'\n",
    "req = requests.get(url)\n",
    "# 페이지가 잘 로드되었는지 체크\n",
    "print('title,content req:',req.status_code)\n",
    "soup = bs(req.text, 'html.parser')\n",
    "# title\n",
    "news_title = soup.select_one('h3.tit_view').text\n",
    "# content\n",
    "news_content = \"\\n\".join(list(map(lambda i:i.text, soup.select('div#harmonyContainer p'))))\n",
    "# 본문 내용이 크므로 100글자만 출력(제대로 담겨있음)\n",
    "print(news_title, news_content[0:100]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 뉴스 하나의 댓글 가져오기\n",
    "## 필요한 정보\n",
    "### 댓글은 response가 도착했을 때 바로 오지 않음\n",
    "web의 network 탭에서 댓글을 불러오는 url을 찾아서 가공해야함.\n",
    "댓글 : headers에 Authorization 값을 첨부하여 params와 함께 요청\n",
    "댓글 개수 : params 없이 headers 값만 첨부하여 요청\n",
    "### 댓글은 한 번에 100개까지만 긁어올 수 있음\n",
    "반복문을 사용하여 100개씩 전부 가져오도록 설정.\n",
    "#### 변경해야 하는 값 : params\n",
    "offset\n",
    "limit\n",
    "### 댓글의 답글은 parentid값을 조정하여 다시 요청해야함\n",
    "#### 변경해야 하는 값 : params\n",
    "parentid\n",
    "### 댓글의 response data는 json 형태로 옴(list로 설정 가능)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:  1221 , current:  1221\n"
     ]
    }
   ],
   "source": [
    "# get comment count\n",
    "# 인증 값(web에서 찾아야 함)\n",
    "auth_code = 'Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJmb3J1bV9rZXkiOiJuZXdzIiwiZ3JhbnRfdHlwZSI6ImFsZXhfY3JlZGVudGlhbHMiLCJzY29wZSI6W10sImV4cCI6MTU5MTg4MzY5MCwiYXV0aG9yaXRpZXMiOlsiUk9MRV9DTElFTlQiXSwianRpIjoiMTQ0NjBhNWQtYTVlMi00NGU0LWFkNzUtZDMyYTNmZDc0MjY1IiwiZm9ydW1faWQiOi05OSwiY2xpZW50X2lkIjoiMjZCWEF2S255NVdGNVowOWxyNWs3N1k4In0.hepLtngDWjpD6PVpCKN4dwSk4w6oyR8Xjeg8x2RvxsU'\n",
    "headers = { \n",
    "    'Authorization': auth_code\n",
    "}\n",
    "url = 'https://comment.daum.net/apis/v1/posts/@20200608091904580'\n",
    "req = requests.get(url, headers=headers)\n",
    "# print('commentCount req:',req.status_code)\n",
    "commentCount = req.json()['commentCount']\n",
    "commentCount\n",
    "# 댓글을 담을 리스트\n",
    "comments_list = []\n",
    "cnt = 0\n",
    "# cnt를 따로 설정한 이유? \n",
    "# comment_list의 값이 답글을 긁어오지 못하면 \n",
    "# commentCount값을 넘을 수 없기 때문.\n",
    "while int(commentCount / 100) >= cnt:\n",
    "    # url 가공\n",
    "    url = f'https://comment.daum.net/apis/v1/posts/@20200608091904580/comments'\n",
    "    params = f'parentId=0&offset={cnt*100}&limit=100&sort=CHRONOLOGICAL&isInitial=true'\n",
    "    params = list(map(lambda i: i.split('='),params.split('&')))\n",
    "    params = {k: v for k, v in params}\n",
    "    req = requests.get(url, headers=headers, params=params) \n",
    "    # response check\n",
    "#     print('comment req:',req.status_code)\n",
    "    # json 가공\n",
    "    comments = list(map(lambda i:i['content'].replace('\\n',''), req.json()))\n",
    "    # list에 저장\n",
    "    comments_list.extend(comments)\n",
    "    cnt = cnt + 1\n",
    "#     # data 확인용 코드\n",
    "#     print('total: ', commentCount, ', current: ', len(comments_list))\n",
    "    # 지연 시간 설정(1초)\n",
    "    time.sleep(0.1)\n",
    "# 답글 긁어오기\n",
    "cnt = 0\n",
    "while int(commentCount / 100) >= cnt:\n",
    "    # url 가공\n",
    "    url = f'https://comment.daum.net/apis/v1/posts/@20200608091904580/comments'\n",
    "    params = f'parentId=-1&offset={cnt*100}&limit=100&sort=CHRONOLOGICAL&isInitial=true'\n",
    "    params = list(map(lambda i: i.split('='),params.split('&')))\n",
    "    params = {k: v for k, v in params}\n",
    "    headers = { \n",
    "        'Authorization': auth_code\n",
    "    }\n",
    "    # request\n",
    "    req = requests.get(url, headers=headers, params=params) \n",
    "#     print('comment req:',req.status_code)\n",
    "    comments = list(map(lambda i:i['content'].replace('\\n',''), req.json()))\n",
    "    comments_list.extend(comments)\n",
    "#     print('total: ', commentCount, ', current: ', len(comments_list))\n",
    "    cnt += 1\n",
    "    time.sleep(0.1)\n",
    "print('total: ', commentCount, ', current: ', len(comments_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 메인 페이지 뉴스 id 전부 가져오기\n",
    "## 필요한 정보\n",
    "### 뉴스 id는 17자리 숫자값\n",
    "### 뉴스 id를 가지고 있는 엘리먼트\n",
    "a.link_txt에서 추출\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20200611105656253',\n",
       " '20200611105614228',\n",
       " '20200611090008538',\n",
       " '20200611104550719',\n",
       " '20200611103458188',\n",
       " '20200611102918864',\n",
       " '20200611103003906',\n",
       " '20200611102113491',\n",
       " '20200611091455299',\n",
       " '20200611094653789',\n",
       " '20200611080954323',\n",
       " '20200611060206595',\n",
       " '20200611105006957',\n",
       " '20200611104738814',\n",
       " '20200611104657793',\n",
       " '20200611104637775',\n",
       " '20200611104517696',\n",
       " '20200611104453654',\n",
       " '20200611104403635',\n",
       " '20200611104312601',\n",
       " '20200611104218555',\n",
       " '20200611103911391',\n",
       " '20200611103552225',\n",
       " '20200611103256065',\n",
       " '20200611075819073',\n",
       " '20200611060137555',\n",
       " '20200611090131623',\n",
       " '20200611102654742',\n",
       " '20200611050048845',\n",
       " '20200611050154881',\n",
       " '20200611102658749',\n",
       " '20200611080037113',\n",
       " '20200611085626422',\n",
       " '20200611094022485',\n",
       " '20200611053957305',\n",
       " '20200611060025455',\n",
       " '20200610143109395',\n",
       " '20200611103040950',\n",
       " '20200611030200994',\n",
       " '20200611050137874',\n",
       " '20200610135519441',\n",
       " '20200610135510433',\n",
       " '20200611030337070',\n",
       " '20200610030500259',\n",
       " '20200610030458257',\n",
       " '20200606030619753']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# news list crawling\n",
    "def get_news_list():\n",
    "    main_req = requests.get('https://news.daum.net/')\n",
    "    main_soup = bs(main_req.text, 'html.parser')\n",
    "    news_list = list(map(lambda i:i.attrs['href'].split('/')[-1], main_soup.select('a.link_txt')))\n",
    "    cnt = 0\n",
    "    for i in range(len(news_list)):\n",
    "        if len(news_list[i - cnt]) != 17:\n",
    "            del news_list[i - cnt]\n",
    "            cnt += 1\n",
    "    return news_list\n",
    "# main의 모든 뉴스를 가져옴\n",
    "news_id_list = get_news_list()\n",
    "news_id_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 반복문으로 main에 있는 모든 뉴스의 제목, 내용, 댓글을 가져와 파일로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "news_id:  20200611105656253\n",
      "total:  0 , current:  0\n",
      "news_id:  20200611105614228\n",
      "total:  0 , current:  0\n",
      "news_id:  20200611090008538\n",
      "total:  105 , current:  105\n",
      "news_id:  20200611104550719\n",
      "total:  18 , current:  18\n",
      "news_id:  20200611103458188\n",
      "total:  17 , current:  17\n",
      "news_id:  20200611102918864\n",
      "total:  60 , current:  60\n",
      "news_id:  20200611103003906\n",
      "total:  96 , current:  96\n",
      "news_id:  20200611102113491\n",
      "total:  15 , current:  15\n",
      "news_id:  20200611091455299\n",
      "total:  39 , current:  39\n",
      "news_id:  20200611094653789\n",
      "total:  1 , current:  1\n",
      "news_id:  20200611080954323\n",
      "total:  0 , current:  0\n",
      "news_id:  20200611060206595\n",
      "total:  0 , current:  0\n",
      "news_id:  20200611105006957\n",
      "total:  7 , current:  7\n",
      "news_id:  20200611104738814\n",
      "total:  163 , current:  163\n",
      "news_id:  20200611104657793\n",
      "total:  14 , current:  14\n",
      "news_id:  20200611104637775\n",
      "total:  27 , current:  27\n",
      "news_id:  20200611104517696\n",
      "total:  9 , current:  9\n",
      "news_id:  20200611104453654\n",
      "total:  1 , current:  1\n",
      "news_id:  20200611104403635\n",
      "total:  5 , current:  5\n",
      "news_id:  20200611104312601\n",
      "total:  2 , current:  2\n",
      "news_id:  20200611104218555\n",
      "total:  15 , current:  15\n",
      "news_id:  20200611103911391\n",
      "total:  3 , current:  3\n",
      "news_id:  20200611103552225\n",
      "total:  17 , current:  17\n",
      "news_id:  20200611103256065\n",
      "total:  5 , current:  5\n",
      "news_id:  20200611075819073\n",
      "total:  113 , current:  113\n",
      "news_id:  20200611060137555\n",
      "total:  243 , current:  243\n",
      "news_id:  20200611090131623\n",
      "total:  4 , current:  4\n",
      "news_id:  20200611102654742\n",
      "total:  27 , current:  27\n",
      "news_id:  20200611050048845\n",
      "total:  917 , current:  917\n",
      "news_id:  20200611050154881\n",
      "total:  4600 , current:  4604\n",
      "news_id:  20200611102658749\n",
      "total:  1199 , current:  1199\n",
      "news_id:  20200611080037113\n",
      "total:  1026 , current:  1026\n",
      "news_id:  20200611085626422\n",
      "total:  805 , current:  805\n",
      "news_id:  20200611094022485\n",
      "total:  608 , current:  608\n",
      "news_id:  20200611053957305\n",
      "total:  1023 , current:  1023\n",
      "news_id:  20200611060025455\n",
      "total:  406 , current:  406\n",
      "news_id:  20200610143109395\n",
      "total:  893 , current:  893\n",
      "news_id:  20200611103040950\n",
      "total:  311 , current:  312\n",
      "news_id:  20200611030200994\n",
      "total:  332 , current:  332\n",
      "news_id:  20200611050137874\n",
      "total:  575 , current:  575\n",
      "news_id:  20200610135519441\n",
      "total:  1975 , current:  1975\n",
      "news_id:  20200610135510433\n",
      "total:  1210 , current:  1210\n",
      "news_id:  20200611030337070\n",
      "total:  0 , current:  0\n",
      "news_id:  20200610030500259\n",
      "total:  0 , current:  0\n",
      "news_id:  20200610030458257\n",
      "total:  7 , current:  7\n",
      "news_id:  20200606030619753\n",
      "total:  0 , current:  0\n",
      "**crawling complete**\n"
     ]
    }
   ],
   "source": [
    "# 제목 list\n",
    "news_title_list = []\n",
    "# 내용 list\n",
    "news_content_list = []\n",
    "# 댓글 list\n",
    "comments_list_all = []\n",
    "# 인증 값(web에서 찾아야 함)\n",
    "headers = {\n",
    "        'Authorization': auth_code\n",
    "}\n",
    "# csv 변환을 위한 list\n",
    "news_list = []\n",
    "# json 변환을 위한 dict\n",
    "news_json = {}\n",
    "\n",
    "for news_id in news_id_list:\n",
    "    print('news_id: ', news_id)\n",
    "# 제목, 내용  \n",
    "    url = f'https://news.v.daum.net/v/{news_id}'\n",
    "    req = requests.get(url)\n",
    "#     # 페이지가 잘 로드되었는지 체크\n",
    "#     print('title,content req:',req.status_code)\n",
    "    soup = bs(req.text, 'html.parser')\n",
    "    # title\n",
    "    news_title = soup.select_one('h3.tit_view').text\n",
    "    # content\n",
    "    news_content = \"\\n\".join(list(map(lambda i:i.text, soup.select('div#harmonyContainer p'))))\n",
    "# 댓글\n",
    "    # get comment count\n",
    "    url = f'https://comment.daum.net/apis/v1/posts/@{news_id}'\n",
    "    req = requests.get(url, headers=headers)\n",
    "#     print('commentCount req:',req.status_code)\n",
    "    commentCount = req.json()['commentCount']\n",
    "    commentCount\n",
    "    # 댓글을 담을 리스트\n",
    "    comments_list = []\n",
    "    cnt = 0\n",
    "    # cnt를 따로 설정한 이유? \n",
    "    # comment_list의 값이 답글을 긁어오지 못하면 \n",
    "    # commentCount값을 넘을 수 없기 때문.\n",
    "    while int(commentCount / 100) >= cnt:\n",
    "        # url 가공\n",
    "        url = f'https://comment.daum.net/apis/v1/posts/@{news_id}/comments'\n",
    "        params = f'parentId=0&offset={cnt*100}&limit=100&sort=CHRONOLOGICAL&isInitial=true'\n",
    "        params = list(map(lambda i: i.split('='),params.split('&')))\n",
    "        params = {k: v for k, v in params}\n",
    "        req = requests.get(url, headers=headers, params=params) \n",
    "        # response check\n",
    "#         print('comment req:',req.status_code)\n",
    "        # json 가공\n",
    "        comments = list(map(lambda i:i['content'].replace('\\n',''), req.json()))\n",
    "        # list에 저장\n",
    "        comments_list.extend(comments)\n",
    "        cnt = cnt + 1\n",
    "#         # data 확인용 코드\n",
    "#         print('total: ', commentCount, ', current: ', len(comments_list))\n",
    "        # 지연 시간 설정(1초)\n",
    "        time.sleep(0.1)\n",
    "    # 답글 긁어오기\n",
    "    cnt = 0\n",
    "    while int(commentCount / 100) >= cnt:\n",
    "        # url 가공\n",
    "        url = f'https://comment.daum.net/apis/v1/posts/@{news_id}/comments'\n",
    "        params = f'parentId=-1&offset={cnt*100}&limit=100&sort=CHRONOLOGICAL&isInitial=true'\n",
    "        params = list(map(lambda i: i.split('='),params.split('&')))\n",
    "        params = {k: v for k, v in params}\n",
    "        headers = {\n",
    "                'Authorization': auth_code\n",
    "        }\n",
    "        # request\n",
    "        req = requests.get(url, headers=headers, params=params) \n",
    "#         print('comment req:',req.status_code)\n",
    "        comments = list(map(lambda i:i['content'].replace('\\n',''), req.json()))\n",
    "        comments_list.extend(comments)\n",
    "#         print('total: ', commentCount, ', current: ', len(comments_list))\n",
    "        cnt += 1\n",
    "        time.sleep(0.1)\n",
    "    print('total: ', commentCount, ', current: ', len(comments_list))\n",
    "    news_title_list.append(news_title)\n",
    "    news_content_list.append(news_content)\n",
    "    comments_list_all.append(comments_list)\n",
    "    \n",
    "# list, dict로 통합\n",
    "news_list = [(news_title_list[i], news_content_list[i], comments_list_all[i]) for i in range(len(news_id_list))]\n",
    "news_json = [{'title': news_title_list[i], 'content': news_content_list[i], 'comments': comments_list_all[i]} for i in range(len(news_id_list))]    \n",
    "# 날짜를 이용하여 파일 이름 생성\n",
    "dt = time.strftime('%Y%m%d', time.localtime(time.time()))\n",
    "xml_file = 'forecast_'+ dt + '.xml'\n",
    "\n",
    "# 파일로 변환\n",
    "io.list_to_csv('news.csv', news_list)\n",
    "io.list_to_json('news.json', news_json)\n",
    "print('**crawling complete**')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 개선사항\n",
    "매일 Authorization 값이 바뀌어 자동화가 불가능\n",
    "\n",
    "search 페이지에서 모든 뉴스id 긁어오는 코드로 개량"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
